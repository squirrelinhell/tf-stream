#!/usr/bin/python3

import sys

if len(sys.argv) < 2:
    sys.stderr.write("\nUsage:\n\n");
    sys.stderr.write("\ttrain_mnist_simple <output.model>\n\n")
    sys.exit(1)

import os
import loadsave
import numpy as np
import tensorflow as tf
import tensorflow.examples.tutorials.mnist as tf_mnist

def dense(x, o):
    i = x.shape[1].value
    sd = 2. / (i + o)
    b = tf.Variable(tf.constant(0.1, shape=[o]))
    w = tf.Variable(tf.random_normal([i, o], stddev=sd))
    return tf.matmul(x, w) + b

def create_model():
    x = tf.placeholder(tf.float32, [None, 28, 28], name="x")

    y = tf.reshape(x, [-1, 28*28])
    y = dense(y, 100)
    y = tf.nn.relu(y)
    y = dense(y, 100)
    y = tf.nn.relu(y)
    y = dense(y, 10)

    t = tf.placeholder(tf.float32, [None, 10], name="t")

    loss = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(labels=t, logits=y),
        name="loss"
    )

    accuracy = tf.reduce_mean(
        tf.cast(
            tf.equal(tf.argmax(y, 1), tf.argmax(t, 1)),
            tf.float32
        ),
        name="accuracy"
    )

    y = tf.nn.softmax(y, 1, name="y")

    global_step = tf.contrib.framework.get_or_create_global_step()

    train = tf.train.GradientDescentOptimizer(0.1).minimize(
        loss,
        global_step = global_step,
        name = "train"
    )

def get_stats(dataset):
    sess = tf.get_default_session()
    x = sess.graph.get_tensor_by_name("x:0")
    t = sess.graph.get_tensor_by_name("t:0")
    loss = sess.graph.get_tensor_by_name("loss:0")
    accuracy = sess.graph.get_tensor_by_name("accuracy:0")

    x_v = np.reshape(dataset.images, [-1, 28, 28])
    v = sess.run(
        [accuracy, loss],
        feed_dict={x: x_v, t: dataset.labels}
    )
    return "accuracy=%f, loss=%f" % (v[0], v[1])

def train_model(next_batch):
    sess = tf.get_default_session()
    x = sess.graph.get_tensor_by_name("x:0")
    t = sess.graph.get_tensor_by_name("t:0")
    loss = sess.graph.get_tensor_by_name("loss:0")
    train = sess.graph.get_operation_by_name("train")

    for _ in range(300):
        x_v, t_v = next_batch()
        x_v = np.reshape(x_v, [-1, 28, 28])
        sess.run(train, feed_dict={x: x_v, t: t_v})

if __name__ == "__main__":
    mnist = tf_mnist.input_data.read_data_sets(
        "__mnist__",
        one_hot = True
    )

    with loadsave.load(sys.argv[1], create_model = create_model) as s:
        print("Training model...")
        for e in range(10):
            train_model(lambda: mnist.train.next_batch(200))
            print(
                "Stats:   [train] ", get_stats(mnist.train),
                "   [test] ", get_stats(mnist.test)
            )
        loadsave.save(s, sys.argv[1])
