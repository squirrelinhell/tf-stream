#!/usr/bin/env python3

import os
import sys
import numpy as np
import tensorflow as tf
import tensorflow.examples.tutorials.mnist as tf_mnist

import loadsave
from utils import *

def dense(x, o):
    i = x.shape[1].value
    sd = 2. / (i + o)
    b = tf.Variable(tf.constant(0.1, shape=[o]))
    w = tf.Variable(tf.random_normal([i, o], stddev=sd))
    return tf.matmul(x, w) + b

def create_model():
    x = tf.placeholder(tf.float32, [None, 28, 28], name="x")

    y = tf.reshape(x, [-1, 28*28])
    y = dense(y, 100)
    y = tf.nn.relu(y)
    y = dense(y, 100)
    y = tf.nn.relu(y)
    y = dense(y, 10)

    t = tf.placeholder(tf.float32, [None, 10], name="t")

    loss = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(labels=t, logits=y),
        name="loss"
    )

    tf.reduce_mean(
        tf.cast(
            tf.equal(tf.argmax(y, 1), tf.argmax(t, 1)),
            tf.float32
        ),
        name="accuracy"
    )

    tf.nn.softmax(y, 1, name="y")

    global_step = tf.contrib.framework.get_or_create_global_step()

    tf.train.GradientDescentOptimizer(0.1).minimize(
        loss,
        global_step = global_step,
        name = "train"
    )

def get_stats(s, dataset):
    v = s.run(
        [s.accuracy, s.loss],
        feed_dict = {s.x: dataset[0], s.t: dataset[1]}
    )
    return "%6.2f%%, loss=%f" % (v[0] * 100.0, v[1])

def train_batch(s, batch):
    s.run(
        s.train,
        feed_dict = {s.x: batch[0], s.t: batch[1]}
    )

def train_epoch(s, train, valid):
    sys.stderr.write("Training model...\n")
    sys.stderr.flush()
    for _ in range(20):
        for b in random_batches(train, 200):
            train_batch(s, b)
        sys.stderr.write("%10d: " % s.global_step.eval())
        sys.stderr.flush()
        sys.stderr.write("  [train] %s" % get_stats(s, train))
        sys.stderr.write("  [valid] %s\n" % get_stats(s, valid))
        sys.stderr.flush()
    loadsave.save(s, sys.argv[1])

def run():
    if len(sys.argv) < 2:
        sys.stderr.write("\nUsage:\n\n");
        sys.stderr.write("\ttrain_mnist_simple <output.model>\n\n")
        sys.exit(1)

    mnist = tf_mnist.input_data.read_data_sets(
        "__mnist__",
        one_hot = True
    )
    with loadsave.load(sys.argv[1], create_model = create_model) as s:
        train_epoch(s,
            (mnist.train.images.reshape((-1, 28, 28)),
                mnist.train.labels),
            (mnist.validation.images.reshape((-1, 28, 28)),
                mnist.validation.labels)
        )

if __name__ == "__main__":
    run()
